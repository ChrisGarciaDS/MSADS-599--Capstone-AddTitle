{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling\n",
    "\n",
    "**University of San Diego, M.S. Applied Data Science**\n",
    "\n",
    "Lai Leng Chan, Minsu Kim, Christopher Garcia\n",
    "\n",
    "This notebook contains predictive  models, model validation as well as model evalaution. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries and packages\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "import seaborn as sns\n",
    "\n",
    "# Preprocessing Packages\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# Modeling packages\n",
    "from sklearn.metrics import log_loss \n",
    "from sklearn.metrics import precision_recall_curve, average_precision_score \n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix, classification_report \n",
    "\n",
    "# Algorithms\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set seed for reproducibility\n",
    "import random\n",
    "random.seed(101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_features(X, scaling_method='minmax'):\n",
    "    \"\"\"\n",
    "    Scale the features in X using Standardization.\n",
    "\n",
    "    Parameters:\n",
    "        X (DataFrame): The features DataFrame to be scaled.\n",
    "        scaling_method (str): The scaling used is Standardization\n",
    "\n",
    "    Returns:\n",
    "        DataFrame: The scaled features DataFrame.\n",
    "    \"\"\"\n",
    "\n",
    "    if scaling_method not in ['standard']:\n",
    "        raise ValueError(\"Invalid scaling_method. Options 'standard'.\")\n",
    "    else:\n",
    "        scaler = StandardScaler()\n",
    "\n",
    "    # Fit and transform the features using the chosen scaler\n",
    "    X_scaled = pd.DataFrame(scaler.fit_transform(X), columns=X.columns)\n",
    "\n",
    "    return X_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Index</th>\n",
       "      <th>Address</th>\n",
       "      <th>FLAG</th>\n",
       "      <th>Avg min between sent tnx</th>\n",
       "      <th>Avg min between received tnx</th>\n",
       "      <th>Time Diff between first and last (Mins)</th>\n",
       "      <th>Sent tnx</th>\n",
       "      <th>Received Tnx</th>\n",
       "      <th>Number of Created Contracts</th>\n",
       "      <th>...</th>\n",
       "      <th>max val sent</th>\n",
       "      <th>avg val sent</th>\n",
       "      <th>min value sent to contract</th>\n",
       "      <th>max val sent to contract</th>\n",
       "      <th>avg value sent to contract</th>\n",
       "      <th>total transactions (including tnx to create contract</th>\n",
       "      <th>total Ether sent</th>\n",
       "      <th>total ether received</th>\n",
       "      <th>total ether sent contracts</th>\n",
       "      <th>total ether balance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0x00009277775ac7d0d59eaad8fee3d10ac6c805e8</td>\n",
       "      <td>0</td>\n",
       "      <td>844.26</td>\n",
       "      <td>1093.71</td>\n",
       "      <td>704785.63</td>\n",
       "      <td>721</td>\n",
       "      <td>89</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>31.220000</td>\n",
       "      <td>1.200681</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>810</td>\n",
       "      <td>865.691093</td>\n",
       "      <td>586.466675</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-279.224419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0x0002b44ddb1476db43c868bd494422ee4c136fed</td>\n",
       "      <td>0</td>\n",
       "      <td>12709.07</td>\n",
       "      <td>2958.44</td>\n",
       "      <td>1218216.73</td>\n",
       "      <td>94</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.800000</td>\n",
       "      <td>0.032844</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>102</td>\n",
       "      <td>3.087297</td>\n",
       "      <td>3.085478</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.001819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0x0002bda54cb772d040f779e88eb453cac0daa244</td>\n",
       "      <td>0</td>\n",
       "      <td>246194.54</td>\n",
       "      <td>2434.02</td>\n",
       "      <td>516729.30</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.538616</td>\n",
       "      <td>1.794308</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12</td>\n",
       "      <td>3.588616</td>\n",
       "      <td>3.589057</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0x00038e6ba2fd5c09aedb96697c8d7b8fa6632e5e</td>\n",
       "      <td>0</td>\n",
       "      <td>10219.60</td>\n",
       "      <td>15785.09</td>\n",
       "      <td>397555.90</td>\n",
       "      <td>25</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>450.000000</td>\n",
       "      <td>70.001834</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>34</td>\n",
       "      <td>1750.045862</td>\n",
       "      <td>895.399559</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-854.646303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0x00062d1dd1afb6fb02540ddad9cdebfe568e0d89</td>\n",
       "      <td>0</td>\n",
       "      <td>36.61</td>\n",
       "      <td>10707.77</td>\n",
       "      <td>382472.42</td>\n",
       "      <td>4598</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.022688</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4619</td>\n",
       "      <td>104.318883</td>\n",
       "      <td>53.421897</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-50.896986</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Index                                     Address  FLAG  \\\n",
       "0           0      1  0x00009277775ac7d0d59eaad8fee3d10ac6c805e8     0   \n",
       "1           1      2  0x0002b44ddb1476db43c868bd494422ee4c136fed     0   \n",
       "2           2      3  0x0002bda54cb772d040f779e88eb453cac0daa244     0   \n",
       "3           3      4  0x00038e6ba2fd5c09aedb96697c8d7b8fa6632e5e     0   \n",
       "4           4      5  0x00062d1dd1afb6fb02540ddad9cdebfe568e0d89     0   \n",
       "\n",
       "   Avg min between sent tnx  Avg min between received tnx  \\\n",
       "0                    844.26                       1093.71   \n",
       "1                  12709.07                       2958.44   \n",
       "2                 246194.54                       2434.02   \n",
       "3                  10219.60                      15785.09   \n",
       "4                     36.61                      10707.77   \n",
       "\n",
       "   Time Diff between first and last (Mins)  Sent tnx  Received Tnx  \\\n",
       "0                                704785.63       721            89   \n",
       "1                               1218216.73        94             8   \n",
       "2                                516729.30         2            10   \n",
       "3                                397555.90        25             9   \n",
       "4                                382472.42      4598            20   \n",
       "\n",
       "   Number of Created Contracts  ...  max val sent  avg val sent  \\\n",
       "0                            0  ...     31.220000      1.200681   \n",
       "1                            0  ...      1.800000      0.032844   \n",
       "2                            0  ...      3.538616      1.794308   \n",
       "3                            0  ...    450.000000     70.001834   \n",
       "4                            1  ...      9.000000      0.022688   \n",
       "\n",
       "   min value sent to contract  max val sent to contract  \\\n",
       "0                         0.0                       0.0   \n",
       "1                         0.0                       0.0   \n",
       "2                         0.0                       0.0   \n",
       "3                         0.0                       0.0   \n",
       "4                         0.0                       0.0   \n",
       "\n",
       "   avg value sent to contract  \\\n",
       "0                         0.0   \n",
       "1                         0.0   \n",
       "2                         0.0   \n",
       "3                         0.0   \n",
       "4                         0.0   \n",
       "\n",
       "   total transactions (including tnx to create contract  total Ether sent  \\\n",
       "0                                                810           865.691093   \n",
       "1                                                102             3.087297   \n",
       "2                                                 12             3.588616   \n",
       "3                                                 34          1750.045862   \n",
       "4                                               4619           104.318883   \n",
       "\n",
       "   total ether received  total ether sent contracts  total ether balance  \n",
       "0            586.466675                         0.0          -279.224419  \n",
       "1              3.085478                         0.0            -0.001819  \n",
       "2              3.589057                         0.0             0.000441  \n",
       "3            895.399559                         0.0          -854.646303  \n",
       "4             53.421897                         0.0           -50.896986  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('C:/Users/annie/Documents/GitHub/MSADS-Capstone-CryptoCurrencyFraudDetection/Data/new_data_file.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-Test Split\n",
    "\n",
    "The data is split into <number> trianing set, <> for a validation set as well as <number> for a testing set. This ensures we have enough data set to test our models since we do not have a large number of observations. The data sets are then saved into separete csv files in order to prepare for modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create training and testing datasets\n",
    "# Save to data folder for modeling\n",
    "# Set random number for reproducibiltiy\n",
    "random_state = 111\n",
    "\n",
    "# Features to be used for model\n",
    "features = df[['total ether received', 'avg val received', 'Unique Received From Addresses', 'Time Diff between first and last (Mins)', \n",
    "               'Received Tnx', 'total transactions (including tnx to create contract', 'Avg min between received tnx', 'Sent tnx',\n",
    "               'total ether balance', 'Avg min between sent tnx']]\n",
    "target_feature = df['FLAG']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training (80%) and temporary rest (20%)\n",
    "X_train_temp, X_test, y_train_temp, y_test = train_test_split(features, target_feature, \n",
    "                                                              test_size=0.2, \n",
    "                                                              random_state=42,\n",
    "                                                              stratify=target_feature)\n",
    "\n",
    "# Split the temporary rest into validation (50%) and testing (50%)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_temp, y_train_temp, \n",
    "                                                  test_size=0.5, \n",
    "                                                  random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Size: 3936\n",
      "Validation Size: 3936\n",
      "Testing Size 1969\n"
     ]
    }
   ],
   "source": [
    "# Check shape of data\n",
    "print('Training Size:', len(X_train))\n",
    "print('Validation Size:', len(X_val))\n",
    "print('Testing Size', len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save new features to \n",
    "X_scaled_train = scale_features(X_train, scaling_method='standard')\n",
    "X_scaled_val = scale_features(X_val, scaling_method='standard')\n",
    "X_scaled_test = scale_features(X_test, scaling_method='standard')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Size: 3936\n",
      "Validation Size: 3936\n",
      "Testing Size 1969\n"
     ]
    }
   ],
   "source": [
    "# Check shape of data\n",
    "print('Training Size:', len(X_scaled_train))\n",
    "print('Validation Size:', len(X_scaled_val))\n",
    "print('Testing Size', len(X_scaled_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 1: Logistic Regression (Baseline Model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression is a binary classification algorithm that models the relationship between the input features and the binary outcome using a logistic function. It predicts the probability of the binary outcome, which can then be thresholded to make binary predictions. It serves as the baseline model to establish a minimum level of performance for fraud detection. By using Logistic Regression as a starting point, we can gauge the performance of more complex models and assess whether their added complexity leads to significantly improved results in identifying fraudulent transactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      1.00      0.88      3105\n",
      "           1       0.00      0.00      0.00       831\n",
      "\n",
      "    accuracy                           0.79      3936\n",
      "   macro avg       0.39      0.50      0.44      3936\n",
      "weighted avg       0.62      0.79      0.70      3936\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Build the logistic regression model\n",
    "logistic_model = LogisticRegression(random_state=random_state)\n",
    "\n",
    "# Fit the model to the training data\n",
    "logistic_model.fit(X_scaled_train, y_train)\n",
    "\n",
    "# Predictions on the validation data\n",
    "y_val_pred = logistic_model.predict(X_scaled_val)\n",
    "\n",
    "# Model evaluation with validation data\n",
    "classification_report_val = classification_report(y_val, y_val_pred)\n",
    "print(\"Classification Report:\\n\", classification_report_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 2: Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest is an ensemble learning method based on decision trees, where multiple trees are built using different subsets of the data and features. It combines their predictions to improve accuracy and reduce overfitting. It is effective in handling complex datasets, provides feature importance insights, and is robust against outliers and irrelevant features, making it well-suited for fraud detection tasks where accurate classification and interpretability are crucial.\n",
    "\n",
    "During Grid Search, param_grid will systematically try all possible combinations of the specified hyperparameters using cross-validation. It evaluates each combination's performance on the validation set and selects the hyperparameter values that result in the best model performance, typically based on a chosen evaluation metric such as accuracy or F1-score. This process helps find the optimal hyperparameters that yield the highest model performance for the given task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'max_depth': 20, 'max_features': 'auto', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 150}\n"
     ]
    }
   ],
   "source": [
    "# Building the initial Random Forest classifier\n",
    "random_forest_model = RandomForestClassifier(random_state=random_state)\n",
    "\n",
    "# Hyperparameter tuning\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 150],  # Number of trees in the forest\n",
    "    'max_depth': [None, 10, 20],     # Maximum depth of the tree\n",
    "    'min_samples_split': [2, 5, 10], # Minimum number of samples required to split an internal node\n",
    "    'min_samples_leaf': [1, 2, 4],   # Minimum number of samples required to be at a leaf node\n",
    "    'max_features': ['auto', 'sqrt', 'log2'],  # Number of features to consider when looking for the best split\n",
    "}\n",
    "\n",
    "# Initialize GridSearchCV to perform hyperparameter tuning\n",
    "grid_search = GridSearchCV(estimator=random_forest_model, param_grid=param_grid, cv=5, n_jobs=-1)\n",
    "\n",
    "# Fit the grid search to the training data\n",
    "grid_search.fit(X_scaled_train, y_train)\n",
    "\n",
    "# Get the best hyperparameters found by GridSearchCV\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Best Hyperparameters:\", best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.61      0.70      3105\n",
      "           1       0.28      0.57      0.37       831\n",
      "\n",
      "    accuracy                           0.60      3936\n",
      "   macro avg       0.56      0.59      0.54      3936\n",
      "weighted avg       0.72      0.60      0.63      3936\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train the model with the best hyperparameters\n",
    "best_random_forest_model = RandomForestClassifier(random_state=random_state, **best_params)\n",
    "best_random_forest_model.fit(X_scaled_train, y_train)\n",
    "\n",
    "# Make predictions on the validation data\n",
    "y_val_pred = best_random_forest_model.predict(X_scaled_val)\n",
    "\n",
    "# Model evaluation with validation data\n",
    "classification_report_val = classification_report(y_val, y_val_pred)\n",
    "print(\"Classification Report:\\n\", classification_report_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "\n",
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
